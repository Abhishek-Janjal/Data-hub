{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eaefbb0-79c4-403d-a187-8f4e99f19294",
   "metadata": {},
   "source": [
    "# Introduction To Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18a6bcf9-495d-4673-a5d9-985308847e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.12/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.5.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Collecting rich (from keras>=3.2.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (2.15.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading h5py-3.12.1-cp312-cp312-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Downloading wrapt-1.17.2-cp312-cp312-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: wrapt, werkzeug, mdurl, markdown, h5py, markdown-it-py, rich\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.41.1 requires blinker<2,>=1.0.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed h5py-3.12.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 rich-13.9.4 werkzeug-3.1.3 wrapt-1.17.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Installation of TensorFlow\n",
    "\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534001b5-6990-4590-9491-ffa8cf973059",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "139bb1ea-7fd5-4884-80fa-5cc297bdc917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4548d16b-2dca-48aa-b6ab-5b8c10a2b02b",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0aade5-145a-4110-9f85-440bac65e7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc1fab-52bc-4132-8ff1-377290551588",
   "metadata": {},
   "source": [
    "| Label\t| Class |\n",
    "|-----|----|\n",
    "|0|\tT-shirt/top|\n",
    "|1|\tTrouser|\n",
    "|2|\tPullover|\n",
    "|3|\tDress|\n",
    "|4|\tCoat|\n",
    "|5|\tSandal|\n",
    "|6|\tShirt|\n",
    "|7|\tSneaker|\n",
    "|8|\tBag|\n",
    "|9|\tAnkle boot|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e514edb-4e90-4c3a-90b9-38f6912ff876",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf59b9-8b25-4270-bbb0-ccf2f24b7755",
   "metadata": {},
   "source": [
    "### Preprocessing - Image Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487d6936-4d1e-45ae-9905-a0accee69a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "Model Setup\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(1028, 1028)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='softmax')\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892d2bbe-99eb-4742-aadf-c71ac6264c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc82c27-11de-4388-a05b-29e64c8a2741",
   "metadata": {},
   "outputs": [],
   "source": [
    "=]model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1cd413-d465-4723-bc82-52dbde7955be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Feeding/Fitting\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10,\n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b285c1c2-2b56-4771-90f2-73a61b37fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation\n",
    "\n",
    "model.evaluate(test_images, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e273301-3293-42c0-ad65-a57252470bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Predictions\n",
    "\n",
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(test_images)\n",
    "\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "class_names[predictions[0]]\n",
    "\n",
    "class_names[test_labels[0]]\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(test_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae450b3-2e67-4144-9dc6-ce57cdd24814",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d722d80f-6abf-4d31-bce6-78cfda93d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Load Dataset\n",
    "\n",
    "data = tf.keras.datasets.cifar10\n",
    " (train_images, train_labels), (test_images, test_labels) = data.load_data()\n",
    "\n",
    "The CIFAR-10 dataset consists of **60000 32x32 colour images** in **10 classes** (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck), with **6000 images per class**. There are **50000 training images** and **10000 test images**.\n",
    "\n",
    "The dataset is divided into **five training batches** and **one test batch**, each with **10000 images**. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly **5000 images** from each class.\n",
    "\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "Normalization\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "Model Setup\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "0.99.  0.003.   0.006   00.  000. 000 000\n",
    "\n",
    "Model Compilation\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "Model Fitting\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10,\n",
    "                    validation_data=(test_images, test_labels))\n",
    "\n",
    "Model Evaluation\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "Epoch VS Accuracy Plot\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a618f68-e493-4723-896f-20aa6e93ad44",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5de92a-911a-4eea-b168-01173f0cbe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "model.add(layers.LSTM(128))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "model.add(layers.GRU(256, return_sequences=True))\n",
    "model.add(layers.SimpleRNN(128))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "encoder_vocab = 1000\n",
    "decoder_vocab = 2000\n",
    "\n",
    "encoder_input = layers.Input(shape=(None,))\n",
    "encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(encoder_input)\n",
    "\n",
    "output, state_h, state_c = layers.LSTM(64, return_state=True, name=\"encoder\")(encoder_embedded)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "decoder_input = layers.Input(shape=(None,))\n",
    "decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=64)(decoder_input)\n",
    "\n",
    "decoder_output = layers.LSTM(64, name=\"decoder\")(decoder_embedded, initial_state=encoder_state)\n",
    "output = layers.Dense(10)(decoder_output)\n",
    "\n",
    "model = tf.keras.Model([encoder_input, decoder_input], output)\n",
    "model.summary()\n",
    "\n",
    "[1, 2, 3, 1, 2, 4, 1, 5, 0]\n",
    "\n",
    "[\n",
    "  [\n",
    "      [23, 23, 23, 23, 23, 23],\n",
    "      [23, 55, 23, 23, 23, 55],\n",
    "      [23, 23, 55, 23, 55, 23],\n",
    "      [23, 23, 23, 55, 23, 23],\n",
    "      [23, 23, 55, 23, 55, 23],\n",
    "      [23, 55, 23, 23, 23, 55],\n",
    "      [23, 23, 23, 23, 23, 23],\n",
    "  ],\n",
    "  [\n",
    "      [23, 23, 23, 23, 23, 23],\n",
    "      [23, 55, 23, 23, 23, 55],\n",
    "      [23, 23, 55, 23, 55, 23],\n",
    "      [23, 23, 23, 55, 23, 23],\n",
    "      [23, 23, 55, 23, 55, 23],\n",
    "      [23, 55, 23, 23, 23, 55],\n",
    "      [23, 23, 23, 23, 23, 23],\n",
    "  ],\n",
    "  [\n",
    "      [23, 23, 23, 23, 23, 23],\n",
    "      [23, 55, 23, 23, 23, 55],\n",
    "      [23, 23, 55, 23, 55, 23],\n",
    "      [23, 23, 23, 55, 23, 23],\n",
    "      [23, 23, 55, 23, 55, 23],\n",
    "      [23, 55, 23, 23, 23, 55],\n",
    "      [23, 23, 23, 23, 23, 23],\n",
    "  ]\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
